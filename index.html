<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CodeRosetta: Pushing the Boundaries of Unsupervised Code
              Translation for Parallel Programming</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://tehrani.xyz">Ali Tehrani</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.cs.iastate.edu/arbhatt9">Arijit Bhattacharjee</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.cs.iastate.edu/lechen">Le Chen</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://nesreenahmed.com/">Nesreen K. Ahmed</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.ayazdan.com/">Amir Yazdanbakhsh</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://swapp.cs.iastate.edu/people/ali-jannesari">Ali Jannesari</a><sup>1</sup>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Iowa State University</span> <br />
              <span class="author-block"><sup>2</sup>Intel Labs</span> <br />
              <span class="author-block"><sup>3</sup>Google DeepMind</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://openreview.net/forum?id=V6hrg4O9gg"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/tehranixyz/CodeRosetta"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>Automatic translation of programming languages has garnered renewed interest, driven by recent
              advancements in large language models (LLMs). Encoder-decoder transformer models, in particular, have
              shown promise in translating between different programming languages. However, translating between a
              language and its high-performance computing (HPC) extension remains underexplored due to inherent
              challenges like complex parallel semantics understanding. In this paper, we introduce CodeRosetta, an
              encoder-decoder transformer model explicitly designed for translating between programming languages and
              also their HPC extensions. CodeRosetta is evaluated on C++ &harr; CUDA and C++ &harr; Fortran translation.
              It employs a customized learning-based framework with tailored pretraining and training objectives to
              effectively capture code semantics and parallel structural nuances, allowing for bidirectional code
              translation. Our results show that CodeRosetta outperforms state-of-the-art baselines in C++ to CUDA
              translation by 2.9 BLEU and 1.72 CodeBLEU points while improving compilation accuracy by 6.05%. Compared
              to general closed-source LLMs, our proposed bidirectional learning-based method improves C++ to CUDA
              translation by 22.08 BLEU and 14.39 CodeBLEU with 2.75% higher compilation accuracy. Finally, CodeRosetta
              exhibits proficiency in Fortran to parallel C++ translation, marking it, to our knowledge, as the first
              encoder-decoder model for such a complex translation task, improving CodeBLEU at least by 4.63 points
              compared to closed-source LLMs and Open Code LLMs.</p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Pretraining and Training Objectives. -->
      <h2 class="title is-3 is-centered has-text-centered">Pretraining and Training Objectives</h2>
      <div class="content has-text-justified">
        <h3>Mask Language Modeling</h3>
        <p>
          Pre-training is essential for transformer models to understand programming languages, and Masked Language
          Modeling (MLM) is used to mask entire words in code, helping the model learn both syntactic and semantic
          patterns. This method, which masks full words like "int" in "int index," helps the model predict the missing
          tokens by understanding the context. Additionally, training the model on a combined dataset of C++ and the
          target language (CUDA or Fortran) enables cross-lingual learning, allowing the model to generalize and
          transfer knowledge across programming languages.
        </p>
      </div>
      <!-- Make sure the figure is full width inside the column -->
      <figure class="image is-fullwidth">
        <img src="static/images/mlm.png" alt="Architecture" style="max-width: 100%; height: auto; object-fit: contain;">
      </figure> <br />
      <div class="content has-text-justified">
        <h3>Abstract Syntaxt Tree Entity Recognition</h3>
        <p>
          Following cross-lingual MLM pre-training, we introduce Abstract Syntax Tree (AST) Entity Recognition (AER) to
          improve CodeRosetta's understanding of code structure. AER allows the model to recognize and categorize
          syntactic elements in code, similar to how Named Entity Recognition works in natural language processing. By
          leveraging ASTs generated from source code, AER pre-training enables CodeRosetta to predict syntactic roles,
          improving its adaptability across different programming languages and paradigms, such as CUDA.
        </p>
      </div>
      <!-- Image follows the same pattern -->
      <figure class="image is-fullwidth">
        <img src="static/images/aer.png" alt="Architecture" style="max-width: 100%; height: auto; object-fit: contain;">
      </figure><br />
      <div class="content has-text-justified">
        <h3>Denoising Auto Encoding</h3>
        <p>
          The decoder in CodeRosetta is untrained after pre-training, so Denoising Auto-Encoding (DAE) is used to train
          it for code translation. DAE involves corrupting input code with various noise types (e.g., token masking,
          shuffling) and training the model to reconstruct the original, enabling the decoder to learn target language
          syntax. Additionally, techniques like weighted token dropping (removing language-specific keywords) and
          language-specific token insertion (inserting tokens from other languages) help the model distinguish between
          programming languages, with adaptive noise ratios gradually increasing complexity during training.
        </p>
      </div>
      <!-- Apply the same technique to all figures -->
      <figure class="image is-fullwidth">
        <img src="static/images/dae.png" alt="Architecture" style="max-width: 100%; height: auto; object-fit: contain;">
      </figure><br />
      <div class="content has-text-justified">
        <h3>Back Translation</h3>
        <p>
          To enhance CodeRosetta's translation quality and grasp of complex code semantics, back translation is
          employed. This process involves translating code from a source to a target language (e.g., C++ to CUDA) and
          then performing reverse translation (CUDA to C++) to reconstruct the original source code. The model refines
          its accuracy by comparing the reconstructed code with the original, iteratively improving its understanding of
          language differences and code structures, while alternating between language pairs to prevent bias and ensure
          balanced learning.
        </p>
      </div>
      <figure class="image is-fullwidth">
        <img src="static/images/bt.png" alt="Architecture" style="max-width: 100%; height: auto; object-fit: contain;">
      </figure><br />
    </div>
  </section>

  <pre id="code-container"></pre>

  <script>
      const code = `__global__ void pow_gpu(int N, float ALPHA,
  float *X, int INCX, float *Y, int INCY) {
      int i = (blockIdx.x + blockIdx.y * gridDim.x) * blockDim.x + threadIdx.x;
      if (i < N) {
          Y[i * INCY] = pow(X[i * INCX], ALPHA);
      }
  }`;
  
      const keywords = /(__global__|void|if|return|pow|gridDim|blockDim|threadIdx|blockIdx)/g; // Regex for keywords
      const types = /(int|float)/g; // Regex for types
      const functions = /pow/g; // Regex for functions
      const operators = /(=|\+|\*|<|\(|\))/g; // Regex for operators
  
      const container = document.getElementById('code-container');
      let index = 0;
  
      function typeCode() {
          if (index < code.length) {
              let char = code[index];
  
              // Check for new lines
              if (char === '\n') {
                  container.innerHTML += '<br>'; // Handle new lines
              } else if (char.match(keywords)) {
                  // If character matches keywords
                  let keywordMatch = code.slice(index).match(keywords);
                  if (keywordMatch) {
                      container.innerHTML += `<span class="keyword">${keywordMatch[0]}</span>`;
                      index += keywordMatch[0].length - 1; // Move the index forward by the length of the keyword
                  }
              } else if (char.match(types)) {
                  // If character matches types
                  let typeMatch = code.slice(index).match(types);
                  if (typeMatch) {
                      container.innerHTML += `<span class="type">${typeMatch[0]}</span>`;
                      index += typeMatch[0].length - 1; // Move the index forward by the length of the type
                  }
              } else if (char.match(functions)) {
                  // If character matches functions
                  let functionMatch = code.slice(index).match(functions);
                  if (functionMatch) {
                      container.innerHTML += `<span class="function">${functionMatch[0]}</span>`;
                      index += functionMatch[0].length - 1; // Move the index forward by the length of the function
                  }
              } else if (char.match(operators)) {
                  // If character matches operators
                  let operatorMatch = code.slice(index).match(operators);
                  if (operatorMatch) {
                      container.innerHTML += `<span class="operator">${operatorMatch[0]}</span>`;
                      index += operatorMatch[0].length - 1; // Move the index forward by the length of the operator
                  }
              } else {
                  container.innerHTML += char; // Append the character
              }
              index++;
              setTimeout(typeCode, 50); // Adjust speed here
          }
      }
  
      typeCode(); // Start the typing effect
  </script>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{
      tehranijamsaz2024coderosetta,
      title={CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming},
      author={TehraniJamsaz, Ali and Bhattacharjee, Arijit and Chen, Le and Ahmed, Nesreen K and Yazdanbakhsh, Amir and Jannesari, Ali},
      booktitle={Proceedings of the 38th International Conference on Neural Information Processing Systems},
      year={2024},
      url={https://openreview.net/forum?id=V6hrg4O9gg}
      }</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/tehranixyz/CodeRosetta" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8 has-text-centered">
          <div class="content">
            <p>
              Template adapted from <a href="http://nerfies.github.io/">Nerfies</a> by Keunhong Park et al.
              and uses <a href="https://bulma.io/">Bulma</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
  

</body>

</html>