<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tehrani.xyz">Ali Tehrani</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.iastate.edu/arbhatt9">Arijit Bhattacharjee</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.iastate.edu/lechen">Le Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://nesreenahmed.com/">Nesreen K. Ahmed</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.ayazdan.com/">Amir Yazdanbakhsh</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://swapp.cs.iastate.edu/people/ali-jannesari">Ali Jannesari</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Iowa State University</span> <br />
            <span class="author-block"><sup>2</sup>Intel Labs</span> <br />
            <span class="author-block"><sup>3</sup>Google DeepMind</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=V6hrg4O9gg"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tehranixyz/CodeRosetta"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>Automatic translation of programming languages has garnered renewed interest, driven by recent advancements in large language models (LLMs). Encoder-decoder transformer models, in particular, have shown promise in translating between different programming languages. However, translating between a language and its high-performance computing (HPC) extension remains underexplored due to inherent challenges like complex parallel semantics understanding. In this paper, we introduce CodeRosetta, an encoder-decoder transformer model explicitly designed for translating between programming languages and also their HPC extensions. CodeRosetta is evaluated on C++ &harr; CUDA and C++ &harr; Fortran translation. It employs a customized learning-based framework with tailored pretraining and training objectives to effectively capture code semantics and parallel structural nuances, allowing for bidirectional code translation. Our results show that CodeRosetta outperforms state-of-the-art baselines in C++ to CUDA translation by 2.9 BLEU and 1.72 CodeBLEU points while improving compilation accuracy by 6.05%. Compared to general closed-source LLMs, our proposed bidirectional learning-based method improves C++ to CUDA translation by 22.08 BLEU and 14.39 CodeBLEU with 2.75% higher compilation accuracy. Finally, CodeRosetta exhibits proficiency in Fortran to parallel C++ translation, marking it, to our knowledge, as the first encoder-decoder model for such a complex translation task, improving CodeBLEU at least by 4.63 points compared to closed-source LLMs and Open Code LLMs.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Pretraining and Training Objectives. -->
    
    <!-- Mask Language Modeling -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pretraining and Training Objectives</h2>
        <div class="content has-text-justified">
          <h3>Mask Language Modeling</h3>
          <p>Pre-training is essential for transformer models to understand programming languages, and Masked Language Modeling (MLM) is used to mask entire words in code, helping the model learn both syntactic and semantic patterns. This method, which masks full words like "int" in "int index," helps the model predict the missing tokens by understanding the context. Additionally, training the model on a combined dataset of C++ and the target language (CUDA or Fortran) enables cross-lingual learning, allowing the model to generalize and transfer knowledge across programming languages.</p>
        </div>
      </div>
    </div>

    <!-- Abstract Syntax Tree Entity Recognition -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3>Abstract Syntax Tree Entity Recognition</h3>
        <p>Following cross-lingual MLM pre-training, we introduce Abstract Syntax Tree (AST) Entity Recognition (AER) to improve CodeRosetta's understanding of code structure. AER allows the model to recognize and categorize syntactic elements in code, similar to how Named Entity Recognition works in natural language processing. By leveraging ASTs generated from source code, AER pre-training enables CodeRosetta to predict syntactic roles, improving its adaptability across different programming languages and paradigms, such as CUDA.</p>
      </div>
    </div>

    <!-- Denoising Auto Encoding -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3>Denoising Auto Encoding</h3>
        <p>The decoder in CodeRosetta is untrained after pre-training, so Denoising Auto-Encoding (DAE) is used to train it for code translation. DAE involves corrupting input code with various noise types (e.g., token masking, shuffling) and training the model to reconstruct the original, enabling the decoder to learn target language syntax. Additionally, techniques like weighted token dropping (removing language-specific keywords) and language-specific token insertion (inserting tokens from other languages) help the model distinguish between programming languages, with adaptive noise ratios gradually increasing complexity during training.</p>
      </div>
    </div>

    <!-- Back Translation -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3>Back Translation</h3>
        <p>To enhance CodeRosetta's translation quality and grasp of complex code semantics, back translation is employed. This process involves translating code from a source to a target language (e.g., C++ to CUDA) and then performing reverse translation (CUDA to C++) to reconstruct the original source code. The model refines its accuracy by comparing the reconstructed code with the original, iteratively improving its understanding of language differences and code structures, while alternating between language pairs to prevent bias and ensure balanced learning.</p>
      </div>
    </div>
    
    <!--/ Pretraining and Training Objectives. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      tehranijamsaz2024coderosetta,
      title={CodeRosetta: Pushing the Boundaries of Unsupervised Code Translation for Parallel Programming},
      author={TehraniJamsaz, Ali and Bhattacharjee, Arijit and Chen, Le and Ahmed, Nesreen K and Yazdanbakhsh, Amir and Jannesari, Ali},
      booktitle={Proceedings of the 38th International Conference on Neural Information Processing Systems},
      year={2024},
      url={https://openreview.net/forum?id=V6hrg4O9gg}
      }</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
      <div class="content has-text-centered">
          <a class="icon-link" href="">
              <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="https://github.com/tehranixyz/CodeRosetta" class="external-link" disabled>
              <i class="fab fa-github"></i>
          </a>
      </div>
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p>
                      Template adapted from <a href="http://nerfies.github.io/">Nerfies</a> by Keunhong Park et
                      al.
                      and uses <a href="https://bulma.io/">Bulma</a>.
                  </p>
              </div>
          </div>
      </div>
  </div>
</footer>

</body>
</html>
